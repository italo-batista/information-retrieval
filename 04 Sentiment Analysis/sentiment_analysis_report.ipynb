{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de sentimento: classificando tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo deste relatório é usar o algoritmo Naive Bayes para classificar tweets como sentimentalmente positivos ou negativos. Desde que esse algoritmo segue uma abordagem de aprendizado supervisionada, precisaremos treinar nosso modelo com uma base de dados já rotulada (tweets rotulados como positivos ou negativos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Este repositório](https://github.com/pauloemmilio/dataset) faz um esforço no sentido de criar essa base de dados já rotulada. A ideia utilizada foi de que se um tweet possui os emoticons ':)' ou ':-)', então ele é positivo e será rotulado assim. Se p tweet tem emoticons ':(' ou ':-(', ele será rotulado como negativo. Utilizamos essa base, que carregaremos a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"../data/tweets_labeled.csv\", encoding=\"utf-8\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa base tem a seguinte cara:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@caprichOreality Fica assim não miga &amp;lt;3 Tud...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Parti me todo a descer a avenida de Gaia com o...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Amanhã é dia de dar um trato na palestra para ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@thankovsky @patorebaichado eu também tenho :)...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ok. Sim. Aham. Tá. De boa. Vai lá. :) https://...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  sentiment\n",
       "0   1  @caprichOreality Fica assim não miga &lt;3 Tud...        1.0\n",
       "1   2  Parti me todo a descer a avenida de Gaia com o...        1.0\n",
       "2   3  Amanhã é dia de dar um trato na palestra para ...        1.0\n",
       "3   4  @thankovsky @patorebaichado eu também tenho :)...        1.0\n",
       "4   5  ok. Sim. Aham. Tá. De boa. Vai lá. :) https://...        1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Todos os tweets estão em português. Ao todo, temos 57483"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(\"\"\"Todos os tweets estão em português. Ao todo, temos {n_tweets}\"\"\".format(n_tweets=tweets.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo algumas constantes\n",
    "(que serão usadas ao longo do código)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_TOKENIZED_TEXT = 'tokenized_text'\n",
    "COL_TEXT = 'text'\n",
    "POSITIVE = 'positive'\n",
    "NEGATIVE = 'negative'\n",
    "COL_PREDICT = 'predict'\n",
    "COL_LABEL = 'label'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento e limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    words = [i for i in text.split() if not i in stopwords]\n",
    "    return (\" \".join(words))\n",
    "\n",
    "def remove_links(text):\n",
    "    text = re.sub(r\"https\\S+\", \"\", text)\n",
    "    return re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "def remove_mentions(text):\n",
    "    return re.sub(r\"@\\w+\", \"\", text)\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text) # remove special chars\n",
    "    text = re.sub(r\"$\\d+\\W+|\\b\\d+\\b|\\W+\\d+$\", \"\", text)\n",
    "    text_with_no_special_chars = re.sub(\"\\s+\", \" \", text) #remove all duplicated spaces\n",
    "    return text_with_no_special_chars\n",
    "\n",
    "def stemming(text):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        words.append(stemmer.stem(word))\n",
    "    return (\" \".join(words))\n",
    "\n",
    "def standardize_text(text):\n",
    "    text = text.lower()\n",
    "    text = remove_links(text)\n",
    "    text = remove_mentions(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = remove_special_chars(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removendo stopwords, alguns caracteres especiais, links e mentions e alterando para lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.text = tweets.text.apply(standardize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Há muitos tweets que são retweets (e portanto tweets com textos exatamente iguais). Tenho a hipótese de que uma imensa quantidade de retweets pode diminuir a acurácia do modelo, pois, depois de passados os tweets para uma forma vetorizada, que explicarei mais embaixo, algumas palavras podem ter um peso maior do que deveriam, dada a grande quantidade de textos repetidos (o modelo pode haver overfitting caso haja muitos retweets). Portanto, iremos removendo os retweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.drop_duplicates(COL_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Agora reduzimos nossa quantidade de tweets para 52760"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(\"\"\"Agora reduzimos nossa quantidade de tweets para {n_tweets}\"\"\".format(n_tweets=tweets.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>fica assim miga lt tudo arranja deus quiser</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>parti todo descer avenida gaia skate</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>amanhã é dia dar trato palestra thedevconf aju...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>posso sentar vocês</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ok sim aham tá boa vai lá</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  sentiment\n",
       "0   1       fica assim miga lt tudo arranja deus quiser         1.0\n",
       "1   2              parti todo descer avenida gaia skate         1.0\n",
       "2   3  amanhã é dia dar trato palestra thedevconf aju...        1.0\n",
       "3   4                                posso sentar vocês         1.0\n",
       "4   5                         ok sim aham tá boa vai lá         1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alterando os valores para a classe de tweets (ex: sentimento positivo deixa de ser representado pelo valor 1 e passar a ser a string 'positive'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_category(sentiment_float):\n",
    "    if sentiment_float == 1.0:\n",
    "        return POSITIVE\n",
    "    else:\n",
    "        return NEGATIVE\n",
    "    \n",
    "tweets.sentiment = tweets.sentiment.apply(get_sentiment_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos usar a implementação da lib [scikit](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB) para o algoritmo Naive Bayes multinomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando os tweets e suas classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fica assim miga lt tudo arranja deus quiser '\n",
      " 'parti todo descer avenida gaia skate '\n",
      " 'amanhã é dia dar trato palestra thedevconf ajustes finais ' ...\n",
      " 'tô quase ' 'vcs sao tudo uns fudido ' 'to legal ']\n"
     ]
    }
   ],
   "source": [
    "tweets_texts = tweets.text.values\n",
    "print(tweets_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'positive' 'positive' ... 'negative' 'negative' 'negative']\n"
     ]
    }
   ],
   "source": [
    "classes = tweets.sentiment.values\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos treinar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"word\")\n",
    "#vectorizer = CountVectorizer(ngram_range = (1, 2))\n",
    "freq_tweets = vectorizer.fit_transform(tweets_texts)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(freq_tweets, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função fit_transform ajusta o modelo, aprende o vocabulário, e transforma os dados de treinamento para uma representação vetorizada com frequêcia das palavras (_bag of words_).\n",
    "\n",
    "Exemplo dessa representação vetorizada seria:\n",
    "\n",
    "id; tweet  \n",
    "1;  \"Este é um tweet positivo\"  \n",
    "2 ; \"Este é um tweet negativo\"  \n",
    "\n",
    "A forma vetorizada seria:  \n",
    "\n",
    "id; Este; é; um; tweet; positivo; negativo; label  \n",
    "1;  1;    1; 1;  1;     1;        0;        1  \n",
    "2;  1;    1; 1;  1;     0;        1;        0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algumas verificações de sanidade.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossos tweets que serão usados para testar o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tests = [\n",
    "    'Esse governo está no início, vamos ver o que vai dar',\n",
    "    'Estou muito feliz com o governo de Minas esse ano',\n",
    "    'O estado de Minas Gerais decretou calamidade financeira!!!',\n",
    "    'A segurança desse país está deixando a desejar',\n",
    "    'O governador de Minas é do PT',\n",
    "    'Estou bastante infeliz ultimamente',\n",
    "    'Menino, tô muito doente']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpando esses tweets, semelhante ao que fizemos com nossa base de dados de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = list(map(standardize_text, raw_tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_testes = vectorizer.transform(tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificando nossos tweets de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = model.predict(freq_testes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 - Tweet: Esse governo está no início, vamos ver o que vai dar. Classified as: positive\n",
      "# 2 - Tweet: Estou muito feliz com o governo de Minas esse ano. Classified as: positive\n",
      "# 3 - Tweet: O estado de Minas Gerais decretou calamidade financeira!!!. Classified as: negative\n",
      "# 4 - Tweet: A segurança desse país está deixando a desejar. Classified as: negative\n",
      "# 5 - Tweet: O governador de Minas é do PT. Classified as: positive\n",
      "# 6 - Tweet: Estou bastante infeliz ultimamente. Classified as: negative\n",
      "# 7 - Tweet: Menino, tô muito doente. Classified as: negative\n"
     ]
    }
   ],
   "source": [
    "for i, tweet in enumerate(zip(raw_tests, classifications)):\n",
    "    text = tweet[0]\n",
    "    classz = tweet[1]\n",
    "    print(\"# {} - Tweet: {}. Classified as: {}\".format(i+1, text, classz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esses tweets usados como testes de sanidade, o modelo parece ter feito sentido. Mas há algumas coisas que poderiam ser melhoradas. Por exemplo, o primeiro tweet poderia ser classificado como neutro. Seria o mais apropriado. Mas como nossos dados de treino só são rotulados ou como positivos ou como negativos, nosso modelo só poderá usar essas duas classes também."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando com dados reais do Twitter (tweets não usados para treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pesquisei pela hashtag #eleicoies2018 usando a API do Twitter e baixei alguns tweets que importaremos agora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test = pd.read_csv(\"../data/tweets_test.csv\", encoding=\"utf-8\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @augustosnunes: #SanatórioGeral Ciro confes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @augustosnunes: #SanatórioGeral Ciro confes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Abreu_Mateus @AdemirAu Não admito que vc fale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @requiaopmdb: Osmar Dias, ex-governo Dilma,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @folha: Defensor de direitos humanos tinha ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  RT @augustosnunes: #SanatórioGeral Ciro confes...\n",
       "1  RT @augustosnunes: #SanatórioGeral Ciro confes...\n",
       "2  @Abreu_Mateus @AdemirAu Não admito que vc fale...\n",
       "3  RT @requiaopmdb: Osmar Dias, ex-governo Dilma,...\n",
       "4  RT @folha: Defensor de direitos humanos tinha ..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test['rawtext'] = tweets_test.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirando os tweets que são retweets (começam com 'RT')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test = tweets_test.loc[~tweets_test[COL_TEXT].str.contains(\"RT @\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removendo duplicados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test = tweets_test.drop_duplicates(COL_TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora iremos selecionar 20 tweets e rotulá-los como positivo ou negativo. A ideia é depois comparar meus rótulos com a classificação dada por nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test = tweets_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> 1 - @Abreu_Mateus @AdemirAu Não admito que vc fale assim com a Dilma. Eu já te disse que eu ❤️ela.\n",
      "\n",
      "~> 2 - Se você está triste hoje, ouça a Dilma e vai doer a barriga de tanto rir. 😂😂😂😂😂😂 \n",
      "\n",
      "~> 3 - Morre advogado Hélio Bicudo, autor do pedido de impeachment de Dilma  via @UOLNoticias @UOL\n",
      "\n",
      "~> 4 - Morre aos 96 anos, em SP, Hélio Bicudo, fundador do PT e autor do pedido de impeachment de Dilma \n",
      "\n",
      "~> 5 - @AbmcGrazi @augustosnunes A Dilma é insuperável nos seus standups.\n",
      "\n",
      "~> 6 - Lula ou Dilma? — eu \n",
      "\n",
      "~> 7 - \"Não voto em Bolsonaro pq ele só fala bobagem e não entende de nada de governo\" afirma o eleitor de Lula e de Dilma. ¬¬\n",
      "\n",
      "~> 8 - Gente ???? ele literalmente ficou um minuto falando da Dilma só pra n responder a pergunta Auahauhaua \n",
      "\n",
      "~> 9 - @arielpalacios @GloboNews pensei que era só tirar a Dilma que ia melhorar! \n",
      "#sqn #LulaLivreJa #golpe\n",
      "\n",
      "~> 10 - @GABRELPlNHElRO O entrevistador Néscio  só faltou dar uma de dilma e dizer que tem que haver diálogo com os bandidos kkkkk\n",
      "\n",
      "~> 11 - @mvsmotta @wyllison @infotimaosccp Quando os manifestoches foram financiados para retirar a Dilma, eles escolheram… \n",
      "\n",
      "~> 12 - @EricAmaral10 Rssss eu tambem acho que o Bolsonaro eh a Dilma de uniforme!\n",
      "\n",
      "~> 13 - - O senhor vai reabrir o arquivo da ditadura?\n",
      "- A senhora Dilma estava onde semana passada? Em Cuba.\n",
      "\n",
      "~> 14 - @luizguiprado @MaiorClubeDeSC Lula e Dilma fizeram o Enem?\n",
      "\n",
      "~> 15 - Lula ou Dilma? — aí eu não sei o lula fez umas cagadas mas ajudou pacas a dilma tmb fez as cagadas dela mas ajudou.… \n",
      "\n",
      "~> 16 - #Dilma Rousseff e #Aécio Neves lideram as pesquisas de intenções de voto para o #Senado em Minas Gerais… \n",
      "\n",
      "~> 17 - Deviam perguntar quantos bancos Dilma assaltou a mão armada, e de quantos sequestros ela participou!!! \n",
      "\n",
      "~> 18 - @VEJA E Nada de Lula, Dilma, Maria do Rosário, Gleici Hoffman, Lindbergh Farias, Haddad,Suplicy, Benedita e o PT de… \n",
      "\n",
      "~> 19 - Osmar Dias, ex-governo Dilma, atribui ao “PT” afastamento de Requião  via @esmaelmorais\n",
      "\n",
      "~> 20 - Pesquisa CNT/MDA aponta Dilma na liderança isolada em Minas  via @brasil247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, tweet in enumerate(tweets_test.text.head(20)):\n",
    "    tweet_without_link = re.sub(r\"https\\S+\", \"\", tweet)\n",
    "    print(\"~> {} - {}\\n\".format(i+1, tweet_without_link))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atribuindo os rótulos que achei apropriado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [POSITIVE, POSITIVE, NEGATIVE, NEGATIVE, POSITIVE, POSITIVE, NEGATIVE, POSITIVE, POSITIVE, POSITIVE, NEGATIVE, POSITIVE, POSITIVE, NEGATIVE, POSITIVE, POSITIVE, NEGATIVE, POSITIVE, NEGATIVE, POSITIVE]\n",
    "tweets_test[COL_LABEL] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpandos os tweets de modo semelhante ao que fiz com os dados treinados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test.text = tweets_test.text.apply(standardize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rawtext</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>admito vc fale assim dilma disse ela</td>\n",
       "      <td>@Abreu_Mateus @AdemirAu Não admito que vc fale...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>triste hoje ouça dilma vai doer barriga tanto ...</td>\n",
       "      <td>Se você está triste hoje, ouça a Dilma e vai d...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>morre advogado hélio bicudo autor pedido impea...</td>\n",
       "      <td>Morre advogado Hélio Bicudo, autor do pedido d...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>morre anos sp hélio bicudo fundador pt autor p...</td>\n",
       "      <td>Morre aos 96 anos, em SP, Hélio Bicudo, fundad...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dilma é insuperável standups</td>\n",
       "      <td>@AbmcGrazi @augustosnunes A Dilma é insuperáve...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "2              admito vc fale assim dilma disse ela    \n",
       "5  triste hoje ouça dilma vai doer barriga tanto ...   \n",
       "6  morre advogado hélio bicudo autor pedido impea...   \n",
       "7  morre anos sp hélio bicudo fundador pt autor p...   \n",
       "8                      dilma é insuperável standups    \n",
       "\n",
       "                                             rawtext     label  \n",
       "2  @Abreu_Mateus @AdemirAu Não admito que vc fale...  positive  \n",
       "5  Se você está triste hoje, ouça a Dilma e vai d...  positive  \n",
       "6  Morre advogado Hélio Bicudo, autor do pedido d...  negative  \n",
       "7  Morre aos 96 anos, em SP, Hélio Bicudo, fundad...  negative  \n",
       "8  @AbmcGrazi @augustosnunes A Dilma é insuperáve...  positive  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformando os tweets para a representação vetorizada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_testes = vectorizer.transform(tweets_test.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando o modelo para classificar os tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test[COL_PREDICT] = model.predict(freq_testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of tweets predicted as positive...\n",
      "\n",
      "~> 1 - @Abreu_Mateus @AdemirAu Não admito que vc fale assim com a Dilma. Eu já te disse que eu ❤️ela.\n",
      "\n",
      "~> 2 - Lula ou Dilma? — eu https://t.co/eiojd2MmKr\n",
      "\n",
      "~> 3 - \"Não voto em Bolsonaro pq ele só fala bobagem e não entende de nada de governo\" afirma o eleitor de Lula e de Dilma. ¬¬\n",
      "\n",
      "~> 4 - Gente ???? ele literalmente ficou um minuto falando da Dilma só pra n responder a pergunta Auahauhaua https://t.co/hgwxcYTIsR\n",
      "\n",
      "~> 5 - @GABRELPlNHElRO O entrevistador Néscio só faltou dar uma de dilma e dizer que tem que haver diálogo com os bandidos kkkkk\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of tweets predicted as positive...\\n\")\n",
    "\n",
    "positive_classified = tweets_test[ tweets_test[COL_PREDICT] == POSITIVE]\n",
    "for i, tweet in enumerate(positive_classified.rawtext.head(5)):\n",
    "    tweet = re.sub(\"\\s+\", \" \", tweet)\n",
    "    print(\"~> {} - {}\\n\".format(i+1, tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Examples of tweets predicted as negative...\n",
      "\n",
      "~> 1 - Se você está triste hoje, ouça a Dilma e vai doer a barriga de tanto rir. 😂😂😂😂😂😂 https://t.co/rJHjTgHilb\n",
      "\n",
      "~> 2 - Morre advogado Hélio Bicudo, autor do pedido de impeachment de Dilma https://t.co/RX3H5mI0np via @UOLNoticias @UOL\n",
      "\n",
      "~> 3 - Morre aos 96 anos, em SP, Hélio Bicudo, fundador do PT e autor do pedido de impeachment de Dilma https://t.co/vGR7bGZRpA\n",
      "\n",
      "~> 4 - @AbmcGrazi @augustosnunes A Dilma é insuperável nos seus standups.\n",
      "\n",
      "~> 5 - @arielpalacios @GloboNews pensei que era só tirar a Dilma que ia melhorar! #sqn #LulaLivreJa #golpe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nExamples of tweets predicted as negative...\\n\")\n",
    "\n",
    "negative_classified = tweets_test[ tweets_test[COL_PREDICT] == NEGATIVE]\n",
    "for i, tweet in enumerate(negative_classified.rawtext.head(5)):\n",
    "    tweet = re.sub(\"\\s+\", \" \", tweet)\n",
    "    tweet = re.sub(\"\\s+\", \" \", tweet)\n",
    "    print(\"~> {} - {}\\n\".format(i+1, tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vendo quatos dos 20 tweets de teste que rotulei foram classificados com o mesmo rótulo que dei:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "n_matches = tweets_test.loc[tweets_test[COL_LABEL] == tweets_test[COL_PREDICT]].shape[0]\n",
    "print(n_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados de modo geral não parecem ser muito satisfatórios. Vale lembrar também que eu posso ter errado também ao rotular os tweets.   \n",
    "Uma coisa que devemos ter em mente também é que os dados usados para treino rotularam de modo muito simplista o sentimento do tweet (se o tweet possui um ':)' ele é positivo; se possui um ':(', é negativo). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outro modo de avaliar o modelo..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função **cross_val_predict** (validação cruzada do modelo) divide os dados do modelo em 10 partes, treina o modelo com nove e testa com uma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_val_predict(model, freq_tweets, classes, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do modelo é de 0.74\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(classes, results)\n",
    "print(\"A acurácia do modelo é de {0:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.77      0.70      0.73     27104\n",
      "   negative       0.71      0.78      0.74     25656\n",
      "\n",
      "avg / total       0.74      0.74      0.74     52760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiments = [POSITIVE, NEGATIVE]\n",
    "print(metrics.classification_report(classes, results, sentiments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outros comentários..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma coisa que identifiquei enquanto construia meu modelo é que usar stemming ou bigrans não influenciou na acurácia do modelo. Testei algumas modificações, mas as perdas ou ganhos não foram consideráveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
