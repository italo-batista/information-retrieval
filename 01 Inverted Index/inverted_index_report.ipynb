{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textblob import TextBlob as tb\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/noticias_estadao.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meeting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data has %d rows and %d columns\" % df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating constants that will be used over this report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_AXIS = 1\n",
    "FULL_REPORT_COLNAME = 'noticia'\n",
    "CONTENT_COLNAME = 'conteudo'\n",
    "TITLE_COLNAME = 'titulo'\n",
    "TOKENS_COLNAME = 'tokens'\n",
    "TERM_COLNAME = 'term'\n",
    "REPORT_ID_COLNAME = 'idNoticia'\n",
    "AND = 'AND'\n",
    "OR = 'OR'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate alls reports' title and content in just one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_report(row):\n",
    "    \"\"\"Concatenate report title and content in just one column.\n",
    "        \n",
    "        Args:\n",
    "            row (:obj: pandas.Series): one row observation from a pandas.DataFrame.            \n",
    "\n",
    "        Return:\n",
    "            str: full report (content with title) in lowercase.\n",
    "    \"\"\"\n",
    "\n",
    "    full_report = row[TITLE_COLNAME] + \" \" + row[CONTENT_COLNAME]\n",
    "    return full_report.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[FULL_REPORT_COLNAME] = df.apply(\n",
    "    lambda row: concatenate_report(row), \n",
    "    axis=COLUMN_AXIS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting just report's id and full content columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[REPORT_ID_COLNAME, FULL_REPORT_COLNAME]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe now looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing report's text and saving tokens in another column in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(row):\n",
    "    \"\"\"Tokenize the text content of a report given as a row from a DataFrame\n",
    "        \n",
    "        Args:\n",
    "            row (:obj: pandas.Series): one row observation from a pandas.DataFrame.            \n",
    "\n",
    "        Return:\n",
    "            set: a report content turned into a set of tokens.\n",
    "    \"\"\"    \n",
    "    \n",
    "    text_blob = tb(row[FULL_REPORT_COLNAME]) \n",
    "    m_tokens = set(text_blob.words)\n",
    "    return m_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[TOKENS_COLNAME] = df.apply(\n",
    "    lambda row: tokenize_text(row), \n",
    "    axis=COLUMN_AXIS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating inverted index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create a intermediate structure called unnested_tokens. This structure will save each token of a report, associating it to the report's id. After this step, we will group this unnested_tokens structure by tokens, getting all reports' ids where one specific token appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnest_tokens_report(unnested_tokens_list, row):\n",
    "    \"\"\"Given a row observation of a DataFrame to represent a report (with content,\n",
    "    tokens and id), iterate over the set of tokens and save each one as a dict with \n",
    "    token value and report id. Each dict is appended in the unnested_tokens_list\n",
    "    passed as param.\n",
    "        \n",
    "    Args:\n",
    "        unnested_tokens_list (list): list of dicts, each dict containing a token value \n",
    "            and the report id where it occured.\n",
    "        row (:obj: pandas.Series): one row observation from a pandas.DataFrame.            \n",
    "    \"\"\"  \n",
    "    \n",
    "    for token in row[TOKENS_COLNAME]:\n",
    "        new_row = {\n",
    "            TERM_COLNAME: token.strip('\\'').strip(),\n",
    "            REPORT_ID_COLNAME: row[REPORT_ID_COLNAME]\n",
    "        }\n",
    "        unnested_tokens_list.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnested_tokens_list = []\n",
    "df.apply(lambda row: unnest_tokens_report(unnested_tokens_list, row), axis=COLUMN_AXIS)\n",
    "\n",
    "print(\"The unnested_tokens_list looks like: \\n\")\n",
    "print(unnested_tokens_list[:9])\n",
    "print(\"\\nThe 'list of dicts' format will be used to create a pandas.DataFrame:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnested_tokens_df = pd.DataFrame(unnested_tokens_list)\n",
    "unnested_tokens_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping by term to create inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedIndexTermOccurrence(object):\n",
    "    \"\"\"Class for register term frequency and docs' ids in which a \n",
    "    term of a inverted index structure appears.\n",
    "    \n",
    "    Attributes:\n",
    "        term_freq (int): Quantity of docs in which term appears.\n",
    "        docs_ids (list): ids of docs in which term appears.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, term_freq, docs_ids):\n",
    "        self.term_freq = term_freq\n",
    "        self.docs_ids = docs_ids\n",
    "    \n",
    "    def get_term_freq(self):\n",
    "        return self.term_freq\n",
    "    \n",
    "    def get_docs_ids(self):\n",
    "        return self.docs_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inverted_index_structure(unnested_tokens_df):\n",
    "    \n",
    "    inverted_index = dict()\n",
    "\n",
    "    for term, obs in unnested_tokens_df.groupby([TERM_COLNAME]):\n",
    "\n",
    "        term_freq = len(obs.get_values())\n",
    "        docs_ids = set(obs[REPORT_ID_COLNAME])\n",
    "\n",
    "        inverted_index[term] = InvertedIndexTermOccurrence(term_freq, docs_ids)\n",
    "    \n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = create_inverted_index_structure(unnested_tokens_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_one_term_query(query):\n",
    "    \n",
    "    empty_str = \"\"\n",
    "    space_str = \" \"\n",
    "    \n",
    "    if query == empty_str:\n",
    "        raise ValueError('You should search for a non empty string.')\n",
    "    \n",
    "    elif query == space_str:\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        return len(query.split(space_str)) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_operator(query):\n",
    "    return AND if AND in query else OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_two_terms(terms_to_search, operator):\n",
    "    \n",
    "    term1 = terms_to_search[0]\n",
    "    term2 = terms_to_search[1]\n",
    "    docs_ids_term1 = inverted_index[term1].get_docs_ids()\n",
    "    docs_ids_term2 = inverted_index[term2].get_docs_ids()                \n",
    "    \n",
    "    if operator == AND:\n",
    "        result = docs_ids_term1 & docs_ids_term2\n",
    "    elif operator == OR:\n",
    "        result = docs_ids_term1 | docs_ids_term2\n",
    "        \n",
    "    return list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, inverted_index):\n",
    "    \n",
    "    if is_one_term_query(query):\n",
    "        return inverted_index[query].get_docs_ids()  \n",
    "    \n",
    "    else:    \n",
    "        operator = get_query_operator(query)\n",
    "        terms_to_search = query.split(\" \" + operator + \" \")\n",
    "        terms_to_search = list(map(lambda term: term.lower(), terms_to_search)) # lowercase all terms to search\n",
    "        \n",
    "        return search_two_terms(terms_to_search, operator)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanities checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Campina AND Grande\"\n",
    "search_result = sorted(search(query, inverted_index))\n",
    "correct_answer = sorted([1952, 4802, 1987, 6694, 5382, 1770, 2763, 1068, 5870, 2777, 1370, 2779])\n",
    "assert search_result == correct_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverted_index = dict()\n",
    "\n",
    "# ROW = 0\n",
    "# for row_index in range(df.shape[ROW]):\n",
    "#     for token in df[TOKENS_COL][row_index]:\n",
    "        \n",
    "#         report_id = data.at[row_index, REPORT_ID_COLNAME]\n",
    "        \n",
    "#         if token in inverted_index:\n",
    "#             inverted_index[token].append(report_id)\n",
    "#         else:\n",
    "#             inverted_index[token] = [report_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As consultas devem ser caseSensitive?\n",
    "E as stopwords?\n",
    "Pode usar funções de set?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
