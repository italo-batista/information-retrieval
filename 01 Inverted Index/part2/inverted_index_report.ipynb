{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "#from textblob import TextBlob as tb\n",
    "import nltk\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/italohmb/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating constants that will be used over this report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLUMN_AXIS = 1\n",
    "FULL_REPORT_COLNAME = 'noticia'\n",
    "CONTENT_COLNAME = 'conteudo'\n",
    "SUBTITLE_COLNAME = 'subTitulo'\n",
    "TITLE_COLNAME = 'titulo'\n",
    "TOKENS_COLNAME = 'tokens'\n",
    "TERM_COLNAME = 'term'\n",
    "REPORT_ID_COLNAME = 'idNoticia'\n",
    "AND = 'AND'\n",
    "OR = 'OR'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meeting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/estadao_noticias_eleicao.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>titulo</th>\n",
       "      <th>subTitulo</th>\n",
       "      <th>conteudo</th>\n",
       "      <th>url</th>\n",
       "      <th>idNoticia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td>PT espera 30 mil pessoas em festa na Esplanada</td>\n",
       "      <td>Objetivo é demonstrar apoio popular a Dilma e ...</td>\n",
       "      <td>BRASÍLIA - Após o desgaste provocado com o lan...</td>\n",
       "      <td>http://politica.estadao.com.br/noticias/geral,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td>Alckmin toma posse de olho no Planalto</td>\n",
       "      <td>Governador reeleito tenta amarrar tucanos paul...</td>\n",
       "      <td>Reeleito em outubro, o governador tucano Geral...</td>\n",
       "      <td>http://politica.estadao.com.br/noticias/geral,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td>Seis obstáculos e desafios do segundo mandato ...</td>\n",
       "      <td>Em meio a escândalo de corrupção, presidente t...</td>\n",
       "      <td>1. Rearranjo das contas A nova equipe econôm...</td>\n",
       "      <td>http://politica.estadao.com.br/noticias/geral,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Veja as principais fotos do dia e dos eventos ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://fotos.estadao.com.br/fotos/politica,dil...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Veja as principais fotos do dia e dos eventos ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://fotos.estadao.com.br/fotos/politica,dil...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp                                             titulo  \\\n",
       "0  2014-12-31T00:00:00Z     PT espera 30 mil pessoas em festa na Esplanada   \n",
       "1  2014-12-31T00:00:00Z             Alckmin toma posse de olho no Planalto   \n",
       "2  2014-12-31T00:00:00Z  Seis obstáculos e desafios do segundo mandato ...   \n",
       "3  2014-12-31T00:00:00Z                                                NaN   \n",
       "4  2014-12-31T00:00:00Z                                                NaN   \n",
       "\n",
       "                                           subTitulo  \\\n",
       "0  Objetivo é demonstrar apoio popular a Dilma e ...   \n",
       "1  Governador reeleito tenta amarrar tucanos paul...   \n",
       "2  Em meio a escândalo de corrupção, presidente t...   \n",
       "3  Veja as principais fotos do dia e dos eventos ...   \n",
       "4  Veja as principais fotos do dia e dos eventos ...   \n",
       "\n",
       "                                            conteudo  \\\n",
       "0  BRASÍLIA - Após o desgaste provocado com o lan...   \n",
       "1  Reeleito em outubro, o governador tucano Geral...   \n",
       "2    1. Rearranjo das contas A nova equipe econôm...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                                 url  idNoticia  \n",
       "0  http://politica.estadao.com.br/noticias/geral,...          1  \n",
       "1  http://politica.estadao.com.br/noticias/geral,...          2  \n",
       "2  http://politica.estadao.com.br/noticias/geral,...          3  \n",
       "3  http://fotos.estadao.com.br/fotos/politica,dil...          4  \n",
       "4  http://fotos.estadao.com.br/fotos/politica,dil...          5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 8716 rows and 6 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"Data has %d rows and %d columns\" % df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenatin galls reports' title and content in just one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concatenate_report(row):\n",
    "    \"\"\"Concatenate report title and content in just one column.\n",
    "        \n",
    "    Args:\n",
    "        row (:obj: pandas.Series): one row observation from a pandas.DataFrame.            \n",
    "\n",
    "    Return:\n",
    "        str: full report (content with title) in lowercase.\n",
    "    \"\"\"\n",
    "    title = str(row[TITLE_COLNAME])\n",
    "    subtitle = str(row[SUBTITLE_COLNAME])\n",
    "    content = str(row[CONTENT_COLNAME])\n",
    "    full_report = title + \" \" + subtitle + \" \" + content\n",
    "    return full_report.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing content values that are NaN (not a number) for an empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empty_str = \"\"\n",
    "df[TITLE_COLNAME].fillna(empty_str, inplace=True)\n",
    "df[SUBTITLE_COLNAME].fillna(empty_str, inplace=True)\n",
    "df[CONTENT_COLNAME].fillna(empty_str, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[FULL_REPORT_COLNAME] = df.apply(\n",
    "    lambda row: concatenate_report(row), axis=COLUMN_AXIS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting just report's id and full content columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[[REPORT_ID_COLNAME, FULL_REPORT_COLNAME]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe now looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idNoticia</th>\n",
       "      <th>noticia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pt espera 30 mil pessoas em festa na esplanada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>alckmin toma posse de olho no planalto governa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>seis obstáculos e desafios do segundo mandato ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>veja as principais fotos do dia e dos eventos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>veja as principais fotos do dia e dos eventos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idNoticia                                            noticia\n",
       "0          1  pt espera 30 mil pessoas em festa na esplanada...\n",
       "1          2  alckmin toma posse de olho no planalto governa...\n",
       "2          3  seis obstáculos e desafios do segundo mandato ...\n",
       "3          4   veja as principais fotos do dia e dos eventos...\n",
       "4          5   veja as principais fotos do dia e dos eventos..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing report's text and saving tokens in another column in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_text(row):\n",
    "    \"\"\"Tokenize the text content of a report given as a row from a DataFrame\n",
    "        \n",
    "    Args:\n",
    "        row (:obj: pandas.Series): one row observation from a pandas.DataFrame.            \n",
    "\n",
    "    Return:\n",
    "        set: a report content turned into a set of tokens.\n",
    "    \"\"\"    \n",
    "    \n",
    "    #text_blob = tb(row[FULL_REPORT_COLNAME]) \n",
    "    #m_tokens = set(text_blob.words)\n",
    "    m_tokens = nltk.word_tokenize(row[FULL_REPORT_COLNAME])\n",
    "    return m_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[TOKENS_COLNAME] = df.apply(\n",
    "    lambda row: tokenize_text(row), axis=COLUMN_AXIS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating inverted index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create a intermediate structure called unnested_tokens. This structure will save each token of a report individually, associating it to the report's id. After this step, we will group this unnested_tokens structure by tokens, getting all reports' ids where one specific token appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unnest_tokens_report(unnested_tokens_list, row):\n",
    "    \"\"\"Given a row observation of a DataFrame to represent a report (with content,\n",
    "    tokens and id), iterate over the set of tokens and save each one as a dict with \n",
    "    token value and report id. Each dict is appended in the unnested_tokens_list\n",
    "    passed as param.\n",
    "        \n",
    "    Args:\n",
    "        unnested_tokens_list (list): list of dicts, each dict containing a token value \n",
    "            and the report id where it occured.\n",
    "        row (:obj: pandas.Series): one row observation from a pandas.DataFrame.            \n",
    "    \"\"\"  \n",
    "    \n",
    "    for token in row[TOKENS_COLNAME]:\n",
    "        new_row = {\n",
    "            TERM_COLNAME: token.strip('\\'').strip(),\n",
    "            REPORT_ID_COLNAME: row[REPORT_ID_COLNAME]}\n",
    "        unnested_tokens_list.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The unnested_tokens_list looks like: \n",
      "\n",
      "[{'term': 'pt', 'idNoticia': 1}, {'term': 'espera', 'idNoticia': 1}, {'term': '30', 'idNoticia': 1}, {'term': 'mil', 'idNoticia': 1}, {'term': 'pessoas', 'idNoticia': 1}, {'term': 'em', 'idNoticia': 1}, {'term': 'festa', 'idNoticia': 1}, {'term': 'na', 'idNoticia': 1}]\n",
      "\n",
      "The 'list of dicts' format will be used to create a pandas.DataFrame:\n"
     ]
    }
   ],
   "source": [
    "unnested_tokens_list = []\n",
    "df.apply(lambda row: unnest_tokens_report(unnested_tokens_list, row), axis=COLUMN_AXIS)\n",
    "\n",
    "print(\"\\nThe unnested_tokens_list looks like: \\n\")\n",
    "print(unnested_tokens_list[:8])\n",
    "print(\"\\nThe 'list of dicts' format will be used to create a pandas.DataFrame:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idNoticia</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>espera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>pessoas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>em</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>festa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>esplanada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>objetivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idNoticia       term\n",
       "0          1         pt\n",
       "1          1     espera\n",
       "2          1         30\n",
       "3          1        mil\n",
       "4          1    pessoas\n",
       "5          1         em\n",
       "6          1      festa\n",
       "7          1         na\n",
       "8          1  esplanada\n",
       "9          1   objetivo"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unnested_tokens_df = pd.DataFrame(unnested_tokens_list)\n",
    "unnested_tokens_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping by term to create inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InvertedIndexTerm:\n",
    "    \"\"\"Class for register term frequency and docs' ids in which a \n",
    "    term of a inverted index structure appears.\n",
    "    \n",
    "    Attributes:\n",
    "        term_freq (int): Quantity of docs in which term appears.\n",
    "        docs_ids (list): ids of docs in which term appears.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, term, freq, docs_ids):\n",
    "        self.term = term\n",
    "        self.freq = freq\n",
    "        self.docs_ids = sorted(list(docs_ids))\n",
    "    \n",
    "    def get_term(self):\n",
    "        return self.term\n",
    "    \n",
    "    def get_freq(self):\n",
    "        return self.freq\n",
    "    \n",
    "    def get_docs_ids(self):\n",
    "        return self.docs_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_inverted_index_structure(unnested_tokens_df):\n",
    "    \"\"\"Create a inverted index structure using python dict structure.\n",
    "    \n",
    "    Args:\n",
    "        unnested_tokens_df (:obj: pandas.DataFrame): unnested tokens of texts from a set of texts.\n",
    "    \n",
    "    Return:\n",
    "        dict: keys are terms found at texts and values are lists of docs_ids where terms are found.\n",
    "    \"\"\"    \n",
    "    inverted_index = dict()\n",
    "\n",
    "    for term, group_itens in unnested_tokens_df.groupby([TERM_COLNAME]):\n",
    "\n",
    "        term_freq = len(group_itens.get_values())\n",
    "        docs_ids = set(group_itens[REPORT_ID_COLNAME])\n",
    "        inverted_index[term] = InvertedIndexTerm(term, term_freq, docs_ids)\n",
    "    \n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the inverted index structure for our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_inverted_index = create_inverted_index_structure(unnested_tokens_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_one_term_query(query):\n",
    "    \n",
    "    empty_str, space_str = \"\", \" \"    \n",
    "    \n",
    "    if query == empty_str or query == space_str:\n",
    "        raise ValueError('You should search for a non empty string.')        \n",
    "    else:\n",
    "        return len(query.split(space_str)) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_query_operator(query):    \n",
    "    \"\"\"Get boolean query operator.\n",
    "    \n",
    "    Args:\n",
    "        query (str): query with more than one term.\n",
    "    \n",
    "    Return:\n",
    "        str: string name for the boolean query operator.\n",
    "    \"\"\"  \n",
    "    \n",
    "    if AND not in query and OR not in query:\n",
    "        raise ValueError('Thats not a valid query.')  \n",
    "    \n",
    "    return AND if AND in query else OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lowercase_iterable_itens(iterable):\n",
    "    \"\"\"Lowercase all itens in a iterable object.\n",
    "    \n",
    "    Args:\n",
    "        iterable (list): list of str itens to lowercase.\n",
    "    \n",
    "    Return:\n",
    "        list: list with elements in lowercase.\n",
    "    \"\"\"      \n",
    "    return list(map(lambda term: term.lower(), iterable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _intersect(list1, list2):\n",
    "    \"\"\"Found all elements that are commom to two lists.\"\"\"           \n",
    "    \n",
    "    result = []    \n",
    "    i, j = 0, 0    \n",
    "    \n",
    "    while i < len(list1) and j < len(list2):    \n",
    "        if list1[i] == list2[j]:\n",
    "            result.append(list1[i])\n",
    "            i += 1\n",
    "            j += 1        \n",
    "        else:            \n",
    "            if list1[i] < list2[j]:\n",
    "                i += 1\n",
    "            else:\n",
    "                j += 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _union(list1, list2):\n",
    "    \"\"\"Found the union (with no repetition) of elements of two given lists.\"\"\"           \n",
    "    \n",
    "    result = []    \n",
    "    i, j = 0, 0\n",
    "    \n",
    "    while i < len(list1) and j < len(list2):    \n",
    "        if list1[i] < list2[j]:\n",
    "            result.append(list1[i])\n",
    "            i += 1      \n",
    "        elif list1[i] > list2[j]:            \n",
    "            result.append(list2[j])\n",
    "            j += 1 \n",
    "        else:\n",
    "            result.append(list1[i])\n",
    "            i += 1\n",
    "            j += 1\n",
    "\n",
    "    while i < len(list1):    \n",
    "        result.append(list1[i])\n",
    "        i += 1      \n",
    "    \n",
    "    while j < len(list2):    \n",
    "        result.append(list2[j])\n",
    "        j += 1      \n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_terms_list_per_freq(terms_list, inverted_index):\n",
    "    \"\"\"Sort list of terms to search by their frequency. Frequency of a term can be found in the InvertedIndexTerm\n",
    "    object saved in the inverted index structure to the corresponding key term.\n",
    "    \n",
    "    Args:\n",
    "        terms_list (list): list to sort.\n",
    "        inverted_index (dict): structure through which get term's frequency.\n",
    "    \n",
    "    Return:\n",
    "        list: sorted list of InvertedIndexTerm objects.\n",
    "    \"\"\"      \n",
    "    terms_obj_list = list(map(lambda term: inverted_index[term], terms_list))    \n",
    "    terms_obj_list.sort(key= lambda term: term.get_freq())\n",
    "    return terms_obj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _boolean_search(terms_to_search, operator, inverted_index):\n",
    "      \n",
    "    sorted_terms_per_freq = sort_terms_list_per_freq(terms_to_search, inverted_index)\n",
    "    \n",
    "    docs_ids = sorted_terms_per_freq[0].get_docs_ids()   \n",
    "    result = docs_ids\n",
    "    \n",
    "    for another_term in sorted_terms_per_freq:\n",
    "        \n",
    "        docs_ids = another_term.get_docs_ids()  \n",
    "    \n",
    "        if operator == AND:\n",
    "            result = _intersect(result, docs_ids)\n",
    "        elif operator == OR:\n",
    "            result = _union(result, docs_ids)\n",
    "            \n",
    "    return list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search(query, inverted_index):\n",
    "    \n",
    "    if is_one_term_query(query):\n",
    "        term = query.lower()\n",
    "        return inverted_index[term].get_docs_ids()  \n",
    "    \n",
    "    else:    \n",
    "        operator = get_query_operator(query)\n",
    "        terms_to_search = query.split(\" \" + operator + \" \")\n",
    "        terms_to_search = lowercase_iterable_itens(terms_to_search)\n",
    "        \n",
    "        return _boolean_search(terms_to_search, operator, inverted_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTE DOIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anotações do lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na representação binária eu que escolho o critério de ranking entre os documentos. O ranking pode ser: \n",
    "- random\n",
    "- precission / recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na verdade a busca binária só vai ser usada pelos outros modelos, já que ela própria não oferece ranking. Os outros modelos usam os resultados da busca binária para poder criar um ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# a decisão de salvar a frequência do documennto em uma estrutura fora do inverted_index\n",
    "# é que por definição o inverted_index só contem a chave termo e o valor docs onde ele aparece e \n",
    "# a frequência do termo em todos os docs\n",
    "\n",
    "def calc_doc_terms_frequency(doc_id, doc_tokens, inverted_index, big_term_freq_dict):\n",
    "    tokens_frequencies = collections.Counter(doc_tokens)\n",
    "    big_term_freq_dict[doc_id] = tokens_frequencies\n",
    "\n",
    "df.apply(\n",
    "    lambda row: calc_doc_terms_frequency(\n",
    "        row[REPORT_ID_COLNAME], row[TOKENS_COLNAME], m_inverted_index, big_term_freq_dict), \n",
    "    axis=COLUMN_AXIS)\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TokenEstimator:\n",
    "    \n",
    "    def __init__(self, df, inverted_index):\n",
    "        self.inverted_index = inverted_index\n",
    "        self.big_term_freq_dict = dict()\n",
    "        self._calc_terms_frequency()\n",
    "        self.df = df\n",
    "    \n",
    "    def _calc_doc_terms_frequency(self, doc_id, doc_tokens):\n",
    "        tokens_frequencies = collections.Counter(doc_tokens)\n",
    "        self.big_term_freq_dict[doc_id] = tokens_frequencies\n",
    "    \n",
    "    def _calc_terms_frequency(self):\n",
    "        df.apply(\n",
    "            lambda row: self._calc_doc_terms_frequency(\n",
    "                row[REPORT_ID_COLNAME], row[TOKENS_COLNAME]), \n",
    "            axis=COLUMN_AXIS)\n",
    "    \n",
    "    def get_tf(self, term, doc_id):\n",
    "        if doc_id not in self.big_term_freq_dict:\n",
    "            raise ValueError('There is no such doc_id in the set of docs.')\n",
    "        return self.big_term_freq_dict[doc_id][term]\n",
    "    \n",
    "    def calc_idf(self, term):\n",
    "        NUMBER_OF_ROWS_INDEX = 0\n",
    "        n_documents = self.df.shape[NUMBER_OF_ROWS_INDEX]\n",
    "        n_containing_term = len(self.inverted_index[term].get_docs_ids())\n",
    "        idf = np.log((n_documents +1) / (n_containing_term))\n",
    "        return idf\n",
    "    \n",
    "    def calc_tfidf(self, term, doc_id):\n",
    "        tf = self.get_tf(term, doc_id)\n",
    "        idf = self.calc_idf(term)\n",
    "        return tf * idf\n",
    "        \n",
    "#    def sim(self, query, doc)        \n",
    "        \n",
    "#        inverted_index_term = self.inverted_index[term]        \n",
    "#        term_docs = term.get_docs_ids()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_estimator = TokenEstimator(df, m_inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scorer(object):\n",
    "    def __init__(self, token_estimator):\n",
    "        self.token_estimator = token_estimator\n",
    "\n",
    "class Binary(Scorer):\n",
    "    def __init__(self):\n",
    "        Scorer.__init_(self)\n",
    "        \n",
    "class TermFrequency(Scorer):\n",
    "\n",
    "    def __init__(self, token_estimator):\n",
    "        Scorer.__init_(self, token_estimator)\n",
    "    \n",
    "    def ranking_search(self, query, search_result):\n",
    "        ranking = []\n",
    "        query_terms = query.split(\" AND \")\n",
    "        for doc_id in search_result:\n",
    "            tf = sim(query_terms, doc_id)\n",
    "            ranking.append((doc_id, tf))\n",
    "        ranking = sorted(ranking, key=lambda t: t[1], reverse=True)\n",
    "        return ranking\n",
    "    \n",
    "    def sim(self, query_terms, doc_id):\n",
    "        tf_accumulated = 0\n",
    "        for query_term in query_terms:\n",
    "            tf = Scorer.token_estimator.get_tf(query_term, doc_id)\n",
    "            tf_accumulated += tf\n",
    "        ranking.append((doc_id, tf_accumulated))        \n",
    "\n",
    "class Idf(Scorer):\n",
    "    def __init__(self):\n",
    "        Scorer.__init__(self)    \n",
    "    \n",
    "class BM25(Scorer):\n",
    "    def __init__(self):\n",
    "        Scorer.__init__(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"segundo AND turno\"\n",
    "# merged_docs_id = search(query, m_inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranking = []\n",
    "# query_terms = query.split(\" AND \")\n",
    "# for doc_id in merged_docs_id:\n",
    "#     tf_accumulated = 0\n",
    "#     for query_term in query_terms:\n",
    "#         tf = token_estimator.get_tf(query_term, doc_id)\n",
    "#         tf_accumulated += tf\n",
    "#     ranking.append((doc_id, tf_accumulated))\n",
    "\n",
    "# sorted(ranking, key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "- unificar token e term para token\n",
    "- idf: np.log(n_documents / (1 + self.n_containing_term(term)))\n",
    "- tf: freq_term / sum_all_freq_in_doc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
