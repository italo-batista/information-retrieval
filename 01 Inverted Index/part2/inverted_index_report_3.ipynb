{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import nltk\n",
    "from time import time\n",
    "from abc import ABC, abstractmethod\n",
    "import re\n",
    "from inverted_index import get_inverted_index\n",
    "from search_engine import search\n",
    "from tokenizer import tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating constants that will be used over this report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_AXIS = 1\n",
    "FULL_REPORT_COLNAME = 'noticia'\n",
    "CONTENT_COLNAME = 'conteudo'\n",
    "SUBTITLE_COLNAME = 'subTitulo'\n",
    "TITLE_COLNAME = 'titulo'\n",
    "TOKENS_COLNAME = 'tokens'\n",
    "TERM_COLNAME = 'term'\n",
    "REPORT_ID_COLNAME = 'idNoticia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/estadao_noticias_eleicao.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating alls reports' title and content in just one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_report(row):\n",
    "    \"\"\"Concatenate report title and content in just one column.\n",
    "        \n",
    "    Args:\n",
    "        row (:obj: pandas.Series): one row observation from a pandas.DataFrame.            \n",
    "\n",
    "    Return:\n",
    "        str: full report (content with title) in lowercase.\n",
    "    \"\"\"\n",
    "    title = str(row[TITLE_COLNAME])\n",
    "    subtitle = str(row[SUBTITLE_COLNAME])\n",
    "    content = str(row[CONTENT_COLNAME])\n",
    "    full_report = title + \" \" + subtitle + \" \" + content\n",
    "    return full_report.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing content values that are NaN (not a number) for an empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_str = \"\"\n",
    "df[TITLE_COLNAME].fillna(empty_str, inplace=True)\n",
    "df[SUBTITLE_COLNAME].fillna(empty_str, inplace=True)\n",
    "df[CONTENT_COLNAME].fillna(empty_str, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[FULL_REPORT_COLNAME] = df.apply(\n",
    "    lambda row: concatenate_report(row), axis=COLUMN_AXIS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting just report's id and full content columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[REPORT_ID_COLNAME, FULL_REPORT_COLNAME]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing report's text and saving tokens in another column in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tokenize(df, FULL_REPORT_COLNAME, TOKENS_COLNAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe now looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idNoticia</th>\n",
       "      <th>noticia</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pt espera 30 mil pessoas em festa na esplanada...</td>\n",
       "      <td>[pt, espera, 30, mil, pessoas, em, festa, na, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>alckmin toma posse de olho no planalto governa...</td>\n",
       "      <td>[alckmin, toma, posse, de, olho, no, planalto,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>seis obstáculos e desafios do segundo mandato ...</td>\n",
       "      <td>[seis, obstáculos, e, desafios, do, segundo, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>veja as principais fotos do dia e dos eventos...</td>\n",
       "      <td>[veja, as, principais, fotos, do, dia, e, dos,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>veja as principais fotos do dia e dos eventos...</td>\n",
       "      <td>[veja, as, principais, fotos, do, dia, e, dos,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idNoticia                                            noticia  \\\n",
       "0          1  pt espera 30 mil pessoas em festa na esplanada...   \n",
       "1          2  alckmin toma posse de olho no planalto governa...   \n",
       "2          3  seis obstáculos e desafios do segundo mandato ...   \n",
       "3          4   veja as principais fotos do dia e dos eventos...   \n",
       "4          5   veja as principais fotos do dia e dos eventos...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [pt, espera, 30, mil, pessoas, em, festa, na, ...  \n",
       "1  [alckmin, toma, posse, de, olho, no, planalto,...  \n",
       "2  [seis, obstáculos, e, desafios, do, segundo, m...  \n",
       "3  [veja, as, principais, fotos, do, dia, e, dos,...  \n",
       "4  [veja, as, principais, fotos, do, dia, e, dos,...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = get_inverted_index(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTE DOIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anotações do lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decisão de salvar a frequência do documennto em uma estrutura fora do inverted_index é que por definição o inverted_index só contem a chave termo e o valor docs onde ele aparece e a frequência do termo em todos os docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TermEstimator:\n",
    "    \n",
    "    def __init__(self, df, inverted_index):\n",
    "        self.df = df\n",
    "        self.big_term_freq_dict = dict()\n",
    "        self.inverted_index = inverted_index\n",
    "        self._calc_terms_frequency()\n",
    "    \n",
    "    def get_tf(self, term, doc_id):\n",
    "        return self.big_term_freq_dict[doc_id][term]\n",
    "    \n",
    "    def calc_idf(self, term):\n",
    "        n_documents = self.get_number_of_docs()\n",
    "        n_containing_term = self.get_number_of_docs_containing(term)\n",
    "        idf = np.log((n_documents + 1) / (n_containing_term))\n",
    "        return idf\n",
    "    \n",
    "    def calc_tfidf(self, term, doc_id):\n",
    "        tf = self.get_tf(term, doc_id)\n",
    "        idf = self.calc_idf(term)\n",
    "        return tf * idf     \n",
    "    \n",
    "    def get_number_of_docs(self):\n",
    "        NUMBER_OF_ROWS_INDEX = 0\n",
    "        n_documents = self.df.shape[NUMBER_OF_ROWS_INDEX] \n",
    "        return n_documents\n",
    "    \n",
    "    def get_number_of_docs_containing(self, term):\n",
    "        return len(self.inverted_index[term].get_docs_ids())\n",
    "    \n",
    "    def _calc_doc_terms_frequency(self, doc_id, doc_terms):\n",
    "        terms_frequencies = collections.Counter(doc_terms)\n",
    "        self.big_term_freq_dict[doc_id] = terms_frequencies\n",
    "    \n",
    "    def _calc_terms_frequency(self):\n",
    "        self.df.apply(\n",
    "            lambda row: self._calc_doc_terms_frequency(\n",
    "                row[REPORT_ID_COLNAME], row[TOKENS_COLNAME]), \n",
    "            axis=COLUMN_AXIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scorer(ABC):\n",
    "    \n",
    "    def __init__(self, term_estimator):\n",
    "        self.term_estimator = term_estimator\n",
    "\n",
    "    @abstractmethod\n",
    "    def sim(self, query_terms, doc_id):\n",
    "        pass\n",
    "        \n",
    "    def ranking_search(self, query, search_result, k):\n",
    "        ranking = []\n",
    "        query_terms = query.split(\" AND \")\n",
    "        for doc_id in search_result:\n",
    "            score = self.sim(query_terms, doc_id)\n",
    "            ranking.append((doc_id, score))\n",
    "        ranking = sorted(ranking, key=lambda t: t[1], reverse=True)\n",
    "        top_k = ranking[:k]\n",
    "        top_k = list(map(lambda x: x[0], top_k))\n",
    "        return top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryScorer(Scorer):\n",
    "    #TO DO: para esse falta retornar o ranking de modo não ordenado, para bater com o gabarito\n",
    "    def __init__(self, term_estimator):\n",
    "        Scorer.__init__(self, term_estimator)\n",
    "        \n",
    "    # essa função poderia ser simplificada retornando a quantidade de termos na query, visto que todos os docs\n",
    "    # retornados num resultado de uma busca (que é uma conjuntiva múltipla) vão ter todos os termos da query\n",
    "    def sim(self, query_terms, doc_id):\n",
    "        n_matches_with_query = 0\n",
    "        for query_term in query_terms:\n",
    "            if doc_id in self.term_estimator.inverted_index[query_term].get_docs_ids():\n",
    "                n_matches_with_query += 1\n",
    "        return n_matches_with_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrequencyScorer(Scorer):\n",
    "\n",
    "    def __init__(self, term_estimator):\n",
    "        Scorer.__init__(self, term_estimator)\n",
    "        \n",
    "    def sim(self, query_terms, doc_id):\n",
    "        tf_accumulated = 0\n",
    "        for query_term in query_terms:\n",
    "            tf = self.term_estimator.get_tf(query_term, doc_id)\n",
    "            tf_accumulated += tf\n",
    "        return tf_accumulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrequencyIDFScorer(Scorer):\n",
    "    \n",
    "    def __init__(self, term_estimator):\n",
    "        Scorer.__init__(self, term_estimator)\n",
    "        \n",
    "    def sim(self, query_terms, doc_id):\n",
    "        tfidf_accumulated = 0\n",
    "        for query_term in query_terms:\n",
    "            tfidf = self.term_estimator.calc_tfidf(query_term, doc_id)\n",
    "            tfidf_accumulated += tfidf\n",
    "        return tfidf_accumulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25Scorer(Scorer):\n",
    "    \n",
    "    def __init__(self, term_estimator):\n",
    "        Scorer.__init__(self, term_estimator)\n",
    "        \n",
    "    def sim(self, query_terms, doc_id):\n",
    "        score_accumulated = 0\n",
    "        for query_term in query_terms:\n",
    "            k = np.random.uniform(low=1.2, high=2)\n",
    "            idf = self.term_estimator.calc_idf(query_term)\n",
    "            tf = self.term_estimator.get_tf(query_term, doc_id)\n",
    "            score = idf * (tf * (k+1) / (tf + k))\n",
    "            score_accumulated += score\n",
    "        return score_accumulated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "querys = [\n",
    "    \"segundo turno\",\n",
    "    \"lava jato\",\n",
    "    \"projeto de lei\",\n",
    "    \"compra de voto\",\n",
    "    \"ministério público\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_estimator = TermEstimator(df, inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_ranked(query, scorer, k=5):\n",
    "    boolean_query = \" AND \".join(query.split(\" \"))\n",
    "    search_result = search(boolean_query, inverted_index)\n",
    "    ranked_result = scorer.ranking_search(boolean_query, search_result, k)\n",
    "    return ranked_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = BinaryScorer(term_estimator)\n",
    "binary_scorer_results = []\n",
    "for query in querys:\n",
    "    result = search_ranked(query, scorer)\n",
    "    binary_scorer_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = FrequencyScorer(term_estimator)\n",
    "frequency_scorer_results = []\n",
    "for query in querys:\n",
    "    result = search_ranked(query, scorer)\n",
    "    frequency_scorer_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = FrequencyIDFScorer(term_estimator)\n",
    "frequency_idf_scorer_results = []\n",
    "for query in querys:\n",
    "    result = search_ranked(query, scorer)\n",
    "    frequency_idf_scorer_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = BM25Scorer(term_estimator)\n",
    "bm25_scorer_results = []\n",
    "for query in querys:\n",
    "    result = search_ranked(query, scorer)\n",
    "    bm25_scorer_results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparando com Gabarito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gabarito = pd.read_csv('gabarito.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from average_precision import mapk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_COL_NAME = 'google'\n",
    "BINARY_SEARCH_COL_NAME = 'busca_binaria'\n",
    "TF_COL_NAME = 'tf'\n",
    "TFIDF_COL_NAME = 'tfidf'\n",
    "BM25_COL_NAME = 'bm25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expected_results(expected_result_type):\n",
    "    expected_answers = []\n",
    "    from_df = gabarito[expected_result_type]\n",
    "    for query_result in from_df:        \n",
    "        as_str = re.sub('[,\\[\\]]', '', query_result)\n",
    "        as_list = as_str.split(\" \")\n",
    "        list_of_int = list(map(int, as_list))\n",
    "        expected_answers.append(list_of_int)\n",
    "    return expected_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparando minhas repostas com os modelos do gabarito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_binary_scorer_results = get_expected_results(BINARY_SEARCH_COL_NAME)\n",
    "expected_frequency_scorer_results = get_expected_results(TF_COL_NAME)\n",
    "expected_frequency_idf_scorer_results = get_expected_results(TFIDF_COL_NAME)\n",
    "expected_bm25_scorer_results = get_expected_results(BM25_COL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9199999999999999\n",
      "1.0\n",
      "0.7606666666666666\n",
      "0.368\n"
     ]
    }
   ],
   "source": [
    "print(mapk(expected_binary_scorer_results, binary_scorer_results, k=5))\n",
    "print(mapk(expected_frequency_scorer_results, frequency_scorer_results, k=5))\n",
    "print(mapk(expected_frequency_idf_scorer_results, frequency_idf_scorer_results, k=5))\n",
    "print(mapk(expected_bm25_scorer_results, bm25_scorer_results, k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_results = get_expected_results(GOOGLE_COL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.048\n",
      "0.08399999999999999\n",
      "0.13999999999999999\n"
     ]
    }
   ],
   "source": [
    "print(mapk(google_results, binary_scorer_results, k=5))\n",
    "print(mapk(google_results, frequency_scorer_results, k=5))\n",
    "print(mapk(google_results, frequency_idf_scorer_results, k=5))\n",
    "print(mapk(google_results, bm25_scorer_results, k=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "- documentar métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
